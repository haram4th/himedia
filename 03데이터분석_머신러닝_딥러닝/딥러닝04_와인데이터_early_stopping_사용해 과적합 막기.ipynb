{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4034dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd52239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/wine.csv\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82216e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af2acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(12, axis=1)\n",
    "y = data[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e1d46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  11\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   5\n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   5\n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   5\n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   6\n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   5\n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...  ..\n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   6\n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   5\n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   6\n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   7\n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   6\n",
       "\n",
       "[6497 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7090cda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "6492    0\n",
       "6493    0\n",
       "6494    0\n",
       "6495    0\n",
       "6496    0\n",
       "Name: 12, Length: 6497, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5100147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71617906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3898, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3fd3443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85a13a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab0f2af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4898\n",
       "1    1599\n",
       "Name: 12, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3906996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "886ce0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                390       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                372       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f03daf0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 42ms/step - loss: 0.7518 - accuracy: 0.7509 - val_loss: 0.4568 - val_accuracy: 0.7764\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4625 - accuracy: 0.7783 - val_loss: 0.4495 - val_accuracy: 0.8103\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.8036 - val_loss: 0.3464 - val_accuracy: 0.8277\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.8262 - val_loss: 0.3104 - val_accuracy: 0.8595\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3005 - accuracy: 0.8621 - val_loss: 0.2579 - val_accuracy: 0.9005\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2529 - accuracy: 0.9104 - val_loss: 0.2339 - val_accuracy: 0.9262\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2208 - accuracy: 0.9309 - val_loss: 0.2185 - val_accuracy: 0.9323\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2137 - accuracy: 0.9312 - val_loss: 0.2209 - val_accuracy: 0.9323\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2111 - accuracy: 0.9316 - val_loss: 0.2175 - val_accuracy: 0.9333\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2041 - accuracy: 0.9323 - val_loss: 0.2112 - val_accuracy: 0.9333\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1996 - accuracy: 0.9329 - val_loss: 0.2077 - val_accuracy: 0.9344\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1971 - accuracy: 0.9326 - val_loss: 0.2055 - val_accuracy: 0.9354\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1952 - accuracy: 0.9323 - val_loss: 0.2044 - val_accuracy: 0.9344\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1927 - accuracy: 0.9326 - val_loss: 0.2046 - val_accuracy: 0.9354\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1913 - accuracy: 0.9336 - val_loss: 0.2043 - val_accuracy: 0.9333\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1899 - accuracy: 0.9336 - val_loss: 0.2021 - val_accuracy: 0.9344\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1879 - accuracy: 0.9336 - val_loss: 0.2005 - val_accuracy: 0.9354\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1867 - accuracy: 0.9333 - val_loss: 0.1998 - val_accuracy: 0.9344\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1851 - accuracy: 0.9333 - val_loss: 0.2003 - val_accuracy: 0.9354\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1843 - accuracy: 0.9367 - val_loss: 0.1987 - val_accuracy: 0.9354\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1838 - accuracy: 0.9347 - val_loss: 0.1971 - val_accuracy: 0.9364\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1821 - accuracy: 0.9353 - val_loss: 0.1976 - val_accuracy: 0.9354\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1813 - accuracy: 0.9374 - val_loss: 0.1962 - val_accuracy: 0.9344\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1807 - accuracy: 0.9347 - val_loss: 0.1948 - val_accuracy: 0.9344\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1799 - accuracy: 0.9357 - val_loss: 0.1950 - val_accuracy: 0.9354\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1796 - accuracy: 0.9371 - val_loss: 0.1945 - val_accuracy: 0.9354\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1787 - accuracy: 0.9371 - val_loss: 0.1936 - val_accuracy: 0.9354\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1781 - accuracy: 0.9357 - val_loss: 0.1934 - val_accuracy: 0.9354\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1780 - accuracy: 0.9377 - val_loss: 0.1924 - val_accuracy: 0.9354\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1771 - accuracy: 0.9381 - val_loss: 0.1919 - val_accuracy: 0.9354\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1764 - accuracy: 0.9381 - val_loss: 0.1917 - val_accuracy: 0.9354\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1758 - accuracy: 0.9384 - val_loss: 0.1913 - val_accuracy: 0.9354\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1757 - accuracy: 0.9394 - val_loss: 0.1900 - val_accuracy: 0.9364\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1750 - accuracy: 0.9388 - val_loss: 0.1897 - val_accuracy: 0.9364\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1745 - accuracy: 0.9405 - val_loss: 0.1908 - val_accuracy: 0.9354\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1741 - accuracy: 0.9398 - val_loss: 0.1891 - val_accuracy: 0.9354\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1734 - accuracy: 0.9388 - val_loss: 0.1887 - val_accuracy: 0.9364\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1728 - accuracy: 0.9391 - val_loss: 0.1880 - val_accuracy: 0.9364\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1723 - accuracy: 0.9391 - val_loss: 0.1881 - val_accuracy: 0.9364\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1719 - accuracy: 0.9401 - val_loss: 0.1871 - val_accuracy: 0.9364\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1716 - accuracy: 0.9394 - val_loss: 0.1861 - val_accuracy: 0.9385\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1717 - accuracy: 0.9384 - val_loss: 0.1874 - val_accuracy: 0.9354\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.9408 - val_loss: 0.1859 - val_accuracy: 0.9385\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1703 - accuracy: 0.9398 - val_loss: 0.1846 - val_accuracy: 0.9385\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1698 - accuracy: 0.9401 - val_loss: 0.1839 - val_accuracy: 0.9385\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1691 - accuracy: 0.9398 - val_loss: 0.1838 - val_accuracy: 0.9385\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1684 - accuracy: 0.9405 - val_loss: 0.1844 - val_accuracy: 0.9374\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1678 - accuracy: 0.9408 - val_loss: 0.1821 - val_accuracy: 0.9385\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1681 - accuracy: 0.9415 - val_loss: 0.1819 - val_accuracy: 0.9405\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1666 - accuracy: 0.9418 - val_loss: 0.1831 - val_accuracy: 0.9385\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.9346\n",
      "loss:  0.18102973699569702\n",
      "accuracy:  0.9346153736114502\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('loss: ', score[0])\n",
    "print('accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca153ea9",
   "metadata": {},
   "source": [
    "# 학습중 loss가 거의 변하지 않을 때 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6feb8a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8121606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./model\\01-0.9477.hdf5\n",
      "\n",
      "Epoch 2: saving model to ./model\\02-0.9477.hdf5\n",
      "\n",
      "Epoch 3: saving model to ./model\\03-0.9477.hdf5\n",
      "\n",
      "Epoch 4: saving model to ./model\\04-0.9467.hdf5\n",
      "\n",
      "Epoch 5: saving model to ./model\\05-0.9487.hdf5\n",
      "\n",
      "Epoch 6: saving model to ./model\\06-0.9487.hdf5\n",
      "\n",
      "Epoch 7: saving model to ./model\\07-0.9487.hdf5\n",
      "\n",
      "Epoch 8: saving model to ./model\\08-0.9477.hdf5\n",
      "\n",
      "Epoch 9: saving model to ./model\\09-0.9508.hdf5\n",
      "\n",
      "Epoch 10: saving model to ./model\\10-0.9528.hdf5\n",
      "\n",
      "Epoch 11: saving model to ./model\\11-0.9487.hdf5\n",
      "\n",
      "Epoch 12: saving model to ./model\\12-0.9538.hdf5\n",
      "\n",
      "Epoch 13: saving model to ./model\\13-0.9518.hdf5\n",
      "\n",
      "Epoch 14: saving model to ./model\\14-0.9497.hdf5\n",
      "\n",
      "Epoch 15: saving model to ./model\\15-0.9549.hdf5\n",
      "\n",
      "Epoch 16: saving model to ./model\\16-0.9528.hdf5\n",
      "\n",
      "Epoch 17: saving model to ./model\\17-0.9579.hdf5\n",
      "\n",
      "Epoch 18: saving model to ./model\\18-0.9528.hdf5\n",
      "\n",
      "Epoch 19: saving model to ./model\\19-0.9621.hdf5\n",
      "\n",
      "Epoch 20: saving model to ./model\\20-0.9692.hdf5\n",
      "\n",
      "Epoch 21: saving model to ./model\\21-0.9713.hdf5\n",
      "\n",
      "Epoch 22: saving model to ./model\\22-0.9692.hdf5\n",
      "\n",
      "Epoch 23: saving model to ./model\\23-0.9692.hdf5\n",
      "\n",
      "Epoch 24: saving model to ./model\\24-0.9631.hdf5\n",
      "\n",
      "Epoch 25: saving model to ./model\\25-0.9723.hdf5\n",
      "\n",
      "Epoch 26: saving model to ./model\\26-0.9703.hdf5\n",
      "\n",
      "Epoch 27: saving model to ./model\\27-0.9682.hdf5\n",
      "\n",
      "Epoch 28: saving model to ./model\\28-0.9703.hdf5\n",
      "\n",
      "Epoch 29: saving model to ./model\\29-0.9733.hdf5\n",
      "\n",
      "Epoch 30: saving model to ./model\\30-0.9692.hdf5\n",
      "\n",
      "Epoch 31: saving model to ./model\\31-0.9713.hdf5\n",
      "\n",
      "Epoch 32: saving model to ./model\\32-0.9692.hdf5\n",
      "\n",
      "Epoch 33: saving model to ./model\\33-0.9723.hdf5\n",
      "\n",
      "Epoch 34: saving model to ./model\\34-0.9713.hdf5\n",
      "\n",
      "Epoch 35: saving model to ./model\\35-0.9733.hdf5\n",
      "\n",
      "Epoch 36: saving model to ./model\\36-0.9723.hdf5\n",
      "\n",
      "Epoch 37: saving model to ./model\\37-0.9713.hdf5\n",
      "\n",
      "Epoch 38: saving model to ./model\\38-0.9682.hdf5\n",
      "\n",
      "Epoch 39: saving model to ./model\\39-0.9733.hdf5\n",
      "\n",
      "Epoch 40: saving model to ./model\\40-0.9733.hdf5\n",
      "\n",
      "Epoch 41: saving model to ./model\\41-0.9723.hdf5\n",
      "\n",
      "Epoch 42: saving model to ./model\\42-0.9754.hdf5\n",
      "\n",
      "Epoch 43: saving model to ./model\\43-0.9723.hdf5\n",
      "\n",
      "Epoch 44: saving model to ./model\\44-0.9703.hdf5\n",
      "\n",
      "Epoch 45: saving model to ./model\\45-0.9713.hdf5\n",
      "\n",
      "Epoch 46: saving model to ./model\\46-0.9723.hdf5\n",
      "\n",
      "Epoch 47: saving model to ./model\\47-0.9754.hdf5\n",
      "\n",
      "Epoch 48: saving model to ./model\\48-0.9744.hdf5\n",
      "\n",
      "Epoch 49: saving model to ./model\\49-0.9733.hdf5\n",
      "\n",
      "Epoch 50: saving model to ./model\\50-0.9744.hdf5\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9777\n",
      "loss:  0.07790879905223846\n",
      "accuracy:  0.9776923060417175\n"
     ]
    }
   ],
   "source": [
    "modelpath = \"./model/{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=500, \n",
    "                    validation_split=0.25, verbose=0, callbacks=[checkpointer])\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('loss: ', score[0])\n",
    "print('accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c090a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_data = pd.DataFrame(history.history, columns=history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d4b2197",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_data['epoch'] = history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48969b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.129704</td>\n",
       "      <td>0.952788</td>\n",
       "      <td>0.137013</td>\n",
       "      <td>0.947692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.128249</td>\n",
       "      <td>0.954157</td>\n",
       "      <td>0.136149</td>\n",
       "      <td>0.947692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.126585</td>\n",
       "      <td>0.955183</td>\n",
       "      <td>0.134178</td>\n",
       "      <td>0.947692</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.126079</td>\n",
       "      <td>0.955525</td>\n",
       "      <td>0.132316</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.125010</td>\n",
       "      <td>0.956209</td>\n",
       "      <td>0.130935</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.124499</td>\n",
       "      <td>0.955867</td>\n",
       "      <td>0.130562</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.123088</td>\n",
       "      <td>0.956551</td>\n",
       "      <td>0.130479</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.122631</td>\n",
       "      <td>0.956894</td>\n",
       "      <td>0.128570</td>\n",
       "      <td>0.947692</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.121806</td>\n",
       "      <td>0.957236</td>\n",
       "      <td>0.126243</td>\n",
       "      <td>0.950769</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.120704</td>\n",
       "      <td>0.957578</td>\n",
       "      <td>0.125349</td>\n",
       "      <td>0.952821</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.121378</td>\n",
       "      <td>0.956894</td>\n",
       "      <td>0.121211</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.119503</td>\n",
       "      <td>0.956894</td>\n",
       "      <td>0.119429</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.120676</td>\n",
       "      <td>0.957578</td>\n",
       "      <td>0.131869</td>\n",
       "      <td>0.951795</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.125063</td>\n",
       "      <td>0.957578</td>\n",
       "      <td>0.119948</td>\n",
       "      <td>0.949744</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.121221</td>\n",
       "      <td>0.958604</td>\n",
       "      <td>0.116066</td>\n",
       "      <td>0.954872</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.121741</td>\n",
       "      <td>0.956894</td>\n",
       "      <td>0.135481</td>\n",
       "      <td>0.952821</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.121516</td>\n",
       "      <td>0.956209</td>\n",
       "      <td>0.121428</td>\n",
       "      <td>0.957949</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.118983</td>\n",
       "      <td>0.962710</td>\n",
       "      <td>0.111639</td>\n",
       "      <td>0.952821</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.111353</td>\n",
       "      <td>0.963394</td>\n",
       "      <td>0.102668</td>\n",
       "      <td>0.962051</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.104999</td>\n",
       "      <td>0.963736</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.101630</td>\n",
       "      <td>0.966473</td>\n",
       "      <td>0.093446</td>\n",
       "      <td>0.971282</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.099125</td>\n",
       "      <td>0.967841</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.098585</td>\n",
       "      <td>0.968868</td>\n",
       "      <td>0.095265</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.097780</td>\n",
       "      <td>0.968868</td>\n",
       "      <td>0.100515</td>\n",
       "      <td>0.963077</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.099315</td>\n",
       "      <td>0.967157</td>\n",
       "      <td>0.091305</td>\n",
       "      <td>0.972308</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.095315</td>\n",
       "      <td>0.966815</td>\n",
       "      <td>0.092478</td>\n",
       "      <td>0.970256</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.093218</td>\n",
       "      <td>0.969210</td>\n",
       "      <td>0.092347</td>\n",
       "      <td>0.968205</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.093004</td>\n",
       "      <td>0.968525</td>\n",
       "      <td>0.089357</td>\n",
       "      <td>0.970256</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.091574</td>\n",
       "      <td>0.969210</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.096828</td>\n",
       "      <td>0.965789</td>\n",
       "      <td>0.091153</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.091442</td>\n",
       "      <td>0.967499</td>\n",
       "      <td>0.087633</td>\n",
       "      <td>0.971282</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.089593</td>\n",
       "      <td>0.969210</td>\n",
       "      <td>0.087716</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.088820</td>\n",
       "      <td>0.971947</td>\n",
       "      <td>0.085259</td>\n",
       "      <td>0.972308</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.087953</td>\n",
       "      <td>0.971947</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.971282</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.086862</td>\n",
       "      <td>0.972289</td>\n",
       "      <td>0.083975</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.089204</td>\n",
       "      <td>0.972631</td>\n",
       "      <td>0.083323</td>\n",
       "      <td>0.972308</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.088345</td>\n",
       "      <td>0.970236</td>\n",
       "      <td>0.083857</td>\n",
       "      <td>0.971282</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.086128</td>\n",
       "      <td>0.969894</td>\n",
       "      <td>0.088162</td>\n",
       "      <td>0.968205</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.088435</td>\n",
       "      <td>0.969894</td>\n",
       "      <td>0.080524</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.090295</td>\n",
       "      <td>0.969894</td>\n",
       "      <td>0.088482</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.086264</td>\n",
       "      <td>0.973657</td>\n",
       "      <td>0.086611</td>\n",
       "      <td>0.972308</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.086056</td>\n",
       "      <td>0.972631</td>\n",
       "      <td>0.082678</td>\n",
       "      <td>0.975385</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.086141</td>\n",
       "      <td>0.968525</td>\n",
       "      <td>0.077770</td>\n",
       "      <td>0.972308</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.083719</td>\n",
       "      <td>0.970578</td>\n",
       "      <td>0.084088</td>\n",
       "      <td>0.970256</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.082510</td>\n",
       "      <td>0.971605</td>\n",
       "      <td>0.078557</td>\n",
       "      <td>0.971282</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.081306</td>\n",
       "      <td>0.973657</td>\n",
       "      <td>0.077072</td>\n",
       "      <td>0.972308</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.077673</td>\n",
       "      <td>0.975026</td>\n",
       "      <td>0.078746</td>\n",
       "      <td>0.975385</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.077372</td>\n",
       "      <td>0.977420</td>\n",
       "      <td>0.076451</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.076295</td>\n",
       "      <td>0.976736</td>\n",
       "      <td>0.076220</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.075089</td>\n",
       "      <td>0.976052</td>\n",
       "      <td>0.075205</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy  epoch\n",
       "0   0.129704  0.952788  0.137013      0.947692      0\n",
       "1   0.128249  0.954157  0.136149      0.947692      1\n",
       "2   0.126585  0.955183  0.134178      0.947692      2\n",
       "3   0.126079  0.955525  0.132316      0.946667      3\n",
       "4   0.125010  0.956209  0.130935      0.948718      4\n",
       "5   0.124499  0.955867  0.130562      0.948718      5\n",
       "6   0.123088  0.956551  0.130479      0.948718      6\n",
       "7   0.122631  0.956894  0.128570      0.947692      7\n",
       "8   0.121806  0.957236  0.126243      0.950769      8\n",
       "9   0.120704  0.957578  0.125349      0.952821      9\n",
       "10  0.121378  0.956894  0.121211      0.948718     10\n",
       "11  0.119503  0.956894  0.119429      0.953846     11\n",
       "12  0.120676  0.957578  0.131869      0.951795     12\n",
       "13  0.125063  0.957578  0.119948      0.949744     13\n",
       "14  0.121221  0.958604  0.116066      0.954872     14\n",
       "15  0.121741  0.956894  0.135481      0.952821     15\n",
       "16  0.121516  0.956209  0.121428      0.957949     16\n",
       "17  0.118983  0.962710  0.111639      0.952821     17\n",
       "18  0.111353  0.963394  0.102668      0.962051     18\n",
       "19  0.104999  0.963736  0.095000      0.969231     19\n",
       "20  0.101630  0.966473  0.093446      0.971282     20\n",
       "21  0.099125  0.967841  0.093595      0.969231     21\n",
       "22  0.098585  0.968868  0.095265      0.969231     22\n",
       "23  0.097780  0.968868  0.100515      0.963077     23\n",
       "24  0.099315  0.967157  0.091305      0.972308     24\n",
       "25  0.095315  0.966815  0.092478      0.970256     25\n",
       "26  0.093218  0.969210  0.092347      0.968205     26\n",
       "27  0.093004  0.968525  0.089357      0.970256     27\n",
       "28  0.091574  0.969210  0.087962      0.973333     28\n",
       "29  0.096828  0.965789  0.091153      0.969231     29\n",
       "30  0.091442  0.967499  0.087633      0.971282     30\n",
       "31  0.089593  0.969210  0.087716      0.969231     31\n",
       "32  0.088820  0.971947  0.085259      0.972308     32\n",
       "33  0.087953  0.971947  0.088494      0.971282     33\n",
       "34  0.086862  0.972289  0.083975      0.973333     34\n",
       "35  0.089204  0.972631  0.083323      0.972308     35\n",
       "36  0.088345  0.970236  0.083857      0.971282     36\n",
       "37  0.086128  0.969894  0.088162      0.968205     37\n",
       "38  0.088435  0.969894  0.080524      0.973333     38\n",
       "39  0.090295  0.969894  0.088482      0.973333     39\n",
       "40  0.086264  0.973657  0.086611      0.972308     40\n",
       "41  0.086056  0.972631  0.082678      0.975385     41\n",
       "42  0.086141  0.968525  0.077770      0.972308     42\n",
       "43  0.083719  0.970578  0.084088      0.970256     43\n",
       "44  0.082510  0.971605  0.078557      0.971282     44\n",
       "45  0.081306  0.973657  0.077072      0.972308     45\n",
       "46  0.077673  0.975026  0.078746      0.975385     46\n",
       "47  0.077372  0.977420  0.076451      0.974359     47\n",
       "48  0.076295  0.976736  0.076220      0.973333     48\n",
       "49  0.075089  0.976052  0.075205      0.974359     49"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b39cb8",
   "metadata": {},
   "source": [
    "# 학습 자동 중단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aef6310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afee74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa10b926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0447 - accuracy: 0.9870 - val_loss: 0.0621 - val_accuracy: 0.9836\n",
      "Epoch 2/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0461 - accuracy: 0.9870 - val_loss: 0.0581 - val_accuracy: 0.9846\n",
      "Epoch 3/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 0.0606 - val_accuracy: 0.9836\n",
      "Epoch 4/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0445 - accuracy: 0.9877 - val_loss: 0.0629 - val_accuracy: 0.9826\n",
      "Epoch 5/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 0.0566 - val_accuracy: 0.9846\n",
      "Epoch 6/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 0.9880 - val_loss: 0.0599 - val_accuracy: 0.9836\n",
      "Epoch 7/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9853 - val_loss: 0.0725 - val_accuracy: 0.9785\n",
      "Epoch 8/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0501 - accuracy: 0.9836 - val_loss: 0.0570 - val_accuracy: 0.9836\n",
      "Epoch 9/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0443 - accuracy: 0.9863 - val_loss: 0.0589 - val_accuracy: 0.9826\n",
      "Epoch 10/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.0646 - val_accuracy: 0.9836\n",
      "Epoch 11/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9867 - val_loss: 0.0574 - val_accuracy: 0.9856\n",
      "Epoch 12/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0433 - accuracy: 0.9873 - val_loss: 0.0560 - val_accuracy: 0.9856\n",
      "Epoch 13/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.0584 - val_accuracy: 0.9867\n",
      "Epoch 14/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 0.9880 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
      "Epoch 15/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0430 - accuracy: 0.9877 - val_loss: 0.0563 - val_accuracy: 0.9836\n",
      "Epoch 16/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 0.9884 - val_loss: 0.0558 - val_accuracy: 0.9856\n",
      "Epoch 17/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9891 - val_loss: 0.0578 - val_accuracy: 0.9826\n",
      "Epoch 18/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9867 - val_loss: 0.0558 - val_accuracy: 0.9856\n",
      "Epoch 19/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9877 - val_loss: 0.0562 - val_accuracy: 0.9836\n",
      "Epoch 20/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9873 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
      "Epoch 21/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0423 - accuracy: 0.9877 - val_loss: 0.0572 - val_accuracy: 0.9856\n",
      "Epoch 22/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9867 - val_loss: 0.0564 - val_accuracy: 0.9836\n",
      "Epoch 23/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0439 - accuracy: 0.9867 - val_loss: 0.0557 - val_accuracy: 0.9856\n",
      "Epoch 24/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9867 - val_loss: 0.0655 - val_accuracy: 0.9815\n",
      "Epoch 25/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9877 - val_loss: 0.0633 - val_accuracy: 0.9836\n",
      "Epoch 26/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
      "Epoch 27/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.0705 - val_accuracy: 0.9795\n",
      "Epoch 28/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0549 - accuracy: 0.9832 - val_loss: 0.0568 - val_accuracy: 0.9856\n",
      "Epoch 29/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0458 - accuracy: 0.9863 - val_loss: 0.0588 - val_accuracy: 0.9836\n",
      "Epoch 30/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
      "Epoch 31/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.0613 - val_accuracy: 0.9826\n",
      "Epoch 32/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0457 - accuracy: 0.9849 - val_loss: 0.0559 - val_accuracy: 0.9836\n",
      "Epoch 33/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0434 - accuracy: 0.9867 - val_loss: 0.0575 - val_accuracy: 0.9826\n",
      "Epoch 34/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 0.0668 - val_accuracy: 0.9815\n",
      "Epoch 35/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0480 - accuracy: 0.9849 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
      "Epoch 36/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 0.9870 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
      "Epoch 37/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.9867 - val_loss: 0.0553 - val_accuracy: 0.9856\n",
      "Epoch 38/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9867 - val_loss: 0.0693 - val_accuracy: 0.9805\n",
      "Epoch 39/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0471 - accuracy: 0.9867 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
      "Epoch 40/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0433 - accuracy: 0.9877 - val_loss: 0.0576 - val_accuracy: 0.9826\n",
      "Epoch 41/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0431 - accuracy: 0.9856 - val_loss: 0.0561 - val_accuracy: 0.9836\n",
      "Epoch 42/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0568 - val_accuracy: 0.9846\n",
      "Epoch 43/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.0570 - val_accuracy: 0.9826\n",
      "Epoch 44/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0434 - accuracy: 0.9870 - val_loss: 0.0575 - val_accuracy: 0.9826\n",
      "Epoch 45/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9856 - val_loss: 0.0627 - val_accuracy: 0.9836\n",
      "Epoch 46/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9849 - val_loss: 0.0576 - val_accuracy: 0.9856\n",
      "Epoch 47/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0455 - accuracy: 0.9849 - val_loss: 0.0606 - val_accuracy: 0.9836\n",
      "Epoch 48/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9870 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
      "Epoch 49/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0418 - accuracy: 0.9880 - val_loss: 0.0551 - val_accuracy: 0.9836\n",
      "Epoch 50/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9880 - val_loss: 0.0554 - val_accuracy: 0.9846\n",
      "Epoch 51/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 0.9867 - val_loss: 0.0557 - val_accuracy: 0.9836\n",
      "Epoch 52/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0415 - accuracy: 0.9873 - val_loss: 0.0548 - val_accuracy: 0.9856\n",
      "Epoch 53/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0417 - accuracy: 0.9877 - val_loss: 0.0565 - val_accuracy: 0.9867\n",
      "Epoch 54/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0409 - accuracy: 0.9884 - val_loss: 0.0550 - val_accuracy: 0.9856\n",
      "Epoch 55/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.0554 - val_accuracy: 0.9846\n",
      "Epoch 56/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.0625 - val_accuracy: 0.9836\n",
      "Epoch 57/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.9856 - val_loss: 0.0569 - val_accuracy: 0.9867\n",
      "Epoch 58/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9856 - val_loss: 0.0686 - val_accuracy: 0.9826\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0450 - accuracy: 0.9873 - val_loss: 0.0610 - val_accuracy: 0.9836\n",
      "Epoch 60/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 0.0559 - val_accuracy: 0.9846\n",
      "Epoch 61/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9873 - val_loss: 0.0553 - val_accuracy: 0.9856\n",
      "Epoch 62/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 0.9880 - val_loss: 0.0547 - val_accuracy: 0.9846\n",
      "Epoch 63/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9873 - val_loss: 0.0566 - val_accuracy: 0.9867\n",
      "Epoch 64/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0406 - accuracy: 0.9880 - val_loss: 0.0544 - val_accuracy: 0.9856\n",
      "Epoch 65/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9887 - val_loss: 0.0577 - val_accuracy: 0.9856\n",
      "Epoch 66/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9870 - val_loss: 0.0551 - val_accuracy: 0.9856\n",
      "Epoch 67/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.0636 - val_accuracy: 0.9856\n",
      "Epoch 68/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.9839 - val_loss: 0.0555 - val_accuracy: 0.9846\n",
      "Epoch 69/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0456 - accuracy: 0.9873 - val_loss: 0.0586 - val_accuracy: 0.9846\n",
      "Epoch 70/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0422 - accuracy: 0.9884 - val_loss: 0.0560 - val_accuracy: 0.9846\n",
      "Epoch 71/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.0556 - val_accuracy: 0.9846\n",
      "Epoch 72/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 0.9880 - val_loss: 0.0597 - val_accuracy: 0.9836\n",
      "Epoch 73/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.0560 - val_accuracy: 0.9867\n",
      "Epoch 74/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9863 - val_loss: 0.0593 - val_accuracy: 0.9836\n",
      "Epoch 75/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.0547 - val_accuracy: 0.9856\n",
      "Epoch 76/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9873 - val_loss: 0.0543 - val_accuracy: 0.9846\n",
      "Epoch 77/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9884 - val_loss: 0.0558 - val_accuracy: 0.9856\n",
      "Epoch 78/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9867 - val_loss: 0.0563 - val_accuracy: 0.9867\n",
      "Epoch 79/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9880 - val_loss: 0.0545 - val_accuracy: 0.9867\n",
      "Epoch 80/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9880 - val_loss: 0.0542 - val_accuracy: 0.9856\n",
      "Epoch 81/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.0549 - val_accuracy: 0.9867\n",
      "Epoch 82/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9877 - val_loss: 0.0561 - val_accuracy: 0.9867\n",
      "Epoch 83/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 0.0540 - val_accuracy: 0.9846\n",
      "Epoch 84/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9891 - val_loss: 0.0541 - val_accuracy: 0.9846\n",
      "Epoch 85/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.0558 - val_accuracy: 0.9846\n",
      "Epoch 86/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.9863 - val_loss: 0.0684 - val_accuracy: 0.9795\n",
      "Epoch 87/2000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0474 - accuracy: 0.9867 - val_loss: 0.0540 - val_accuracy: 0.9846\n",
      "Epoch 88/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 0.9880 - val_loss: 0.0636 - val_accuracy: 0.9856\n",
      "Epoch 89/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9860 - val_loss: 0.0547 - val_accuracy: 0.9836\n",
      "Epoch 90/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 0.0597 - val_accuracy: 0.9846\n",
      "Epoch 91/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0457 - accuracy: 0.9877 - val_loss: 0.0542 - val_accuracy: 0.9856\n",
      "Epoch 92/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9884 - val_loss: 0.0604 - val_accuracy: 0.9846\n",
      "Epoch 93/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0463 - accuracy: 0.9863 - val_loss: 0.0570 - val_accuracy: 0.9856\n",
      "Epoch 94/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9870 - val_loss: 0.0562 - val_accuracy: 0.9867\n",
      "Epoch 95/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9877 - val_loss: 0.0543 - val_accuracy: 0.9836\n",
      "Epoch 96/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9873 - val_loss: 0.0548 - val_accuracy: 0.9856\n",
      "Epoch 97/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9873 - val_loss: 0.0548 - val_accuracy: 0.9856\n",
      "Epoch 98/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.0566 - val_accuracy: 0.9867\n",
      "Epoch 99/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0402 - accuracy: 0.9884 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
      "Epoch 100/2000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0397 - accuracy: 0.9884 - val_loss: 0.0538 - val_accuracy: 0.9846\n",
      "Epoch 101/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.0543 - val_accuracy: 0.9856\n",
      "Epoch 102/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9891 - val_loss: 0.0561 - val_accuracy: 0.9856\n",
      "Epoch 103/2000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0388 - accuracy: 0.9897 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
      "Epoch 104/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 0.0546 - val_accuracy: 0.9856\n",
      "Epoch 105/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.0539 - val_accuracy: 0.9856\n",
      "Epoch 106/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 0.9891 - val_loss: 0.0541 - val_accuracy: 0.9856\n",
      "Epoch 107/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0381 - accuracy: 0.9884 - val_loss: 0.0545 - val_accuracy: 0.9856\n",
      "Epoch 108/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9891 - val_loss: 0.0659 - val_accuracy: 0.9805\n",
      "Epoch 109/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0462 - accuracy: 0.9853 - val_loss: 0.0539 - val_accuracy: 0.9836\n",
      "Epoch 110/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.0556 - val_accuracy: 0.9836\n",
      "Epoch 111/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.0574 - val_accuracy: 0.9846\n",
      "Epoch 112/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9884 - val_loss: 0.0543 - val_accuracy: 0.9856\n",
      "Epoch 113/2000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0388 - accuracy: 0.9887 - val_loss: 0.0536 - val_accuracy: 0.9846\n",
      "Epoch 114/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9887 - val_loss: 0.0584 - val_accuracy: 0.9867\n",
      "Epoch 115/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9873 - val_loss: 0.0622 - val_accuracy: 0.9836\n",
      "Epoch 116/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0558 - val_accuracy: 0.9836\n",
      "Epoch 117/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9887 - val_loss: 0.0554 - val_accuracy: 0.9856\n",
      "Epoch 118/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9873 - val_loss: 0.0607 - val_accuracy: 0.9836\n",
      "Epoch 119/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9863 - val_loss: 0.0561 - val_accuracy: 0.9836\n",
      "Epoch 120/2000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 0.9884 - val_loss: 0.0534 - val_accuracy: 0.9846\n",
      "Epoch 121/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9880 - val_loss: 0.0554 - val_accuracy: 0.9856\n",
      "Epoch 122/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9884 - val_loss: 0.0565 - val_accuracy: 0.9856\n",
      "Epoch 123/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9884 - val_loss: 0.0551 - val_accuracy: 0.9856\n",
      "Epoch 124/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 0.0540 - val_accuracy: 0.9836\n",
      "Epoch 125/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0386 - accuracy: 0.9880 - val_loss: 0.0578 - val_accuracy: 0.9856\n",
      "Epoch 126/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9894 - val_loss: 0.0540 - val_accuracy: 0.9846\n",
      "Epoch 127/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.0557 - val_accuracy: 0.9836\n",
      "Epoch 128/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9873 - val_loss: 0.0544 - val_accuracy: 0.9856\n",
      "Epoch 129/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.0567 - val_accuracy: 0.9856\n",
      "Epoch 130/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 0.9891 - val_loss: 0.0607 - val_accuracy: 0.9846\n",
      "Epoch 131/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9870 - val_loss: 0.0596 - val_accuracy: 0.9856\n",
      "Epoch 132/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.9867 - val_loss: 0.0569 - val_accuracy: 0.9856\n",
      "Epoch 133/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.9843 - val_loss: 0.0713 - val_accuracy: 0.9815\n",
      "Epoch 134/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.9839 - val_loss: 0.0552 - val_accuracy: 0.9826\n",
      "Epoch 135/2000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9870 - val_loss: 0.0644 - val_accuracy: 0.9795\n",
      "Epoch 136/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9873 - val_loss: 0.0574 - val_accuracy: 0.9856\n",
      "Epoch 137/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9873 - val_loss: 0.0543 - val_accuracy: 0.9856\n",
      "Epoch 138/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.0541 - val_accuracy: 0.9856\n",
      "Epoch 139/2000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9891 - val_loss: 0.0547 - val_accuracy: 0.9856\n",
      "Epoch 140/2000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 0.0535 - val_accuracy: 0.9856\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.0493 - accuracy: 0.9877\n",
      "loss:  0.049282390624284744\n",
      "accuracy:  0.9876922965049744\n"
     ]
    }
   ],
   "source": [
    "modelpath = \"./model/{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor = 'val_loss', verbose=0,\n",
    "                              save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=2000, batch_size=500, \n",
    "                    validation_split=0.25, verbose=1, \n",
    "                    callbacks=[early_stopping_callback, checkpointer])\n",
    "score = model.evaluate(data2_X, data2_y)\n",
    "print('loss: ', score[0])\n",
    "print('accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70583f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(history.history, columns=history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a27c0b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.043804</td>\n",
       "      <td>0.985973</td>\n",
       "      <td>0.057355</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.040324</td>\n",
       "      <td>0.988368</td>\n",
       "      <td>0.054346</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.038798</td>\n",
       "      <td>0.988710</td>\n",
       "      <td>0.053584</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.039561</td>\n",
       "      <td>0.988710</td>\n",
       "      <td>0.058421</td>\n",
       "      <td>0.986667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.043663</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.062238</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.040798</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.055796</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.040098</td>\n",
       "      <td>0.988710</td>\n",
       "      <td>0.055392</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.043736</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.060652</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.039868</td>\n",
       "      <td>0.986315</td>\n",
       "      <td>0.056128</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.040674</td>\n",
       "      <td>0.988368</td>\n",
       "      <td>0.053366</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.041093</td>\n",
       "      <td>0.988026</td>\n",
       "      <td>0.055438</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.039716</td>\n",
       "      <td>0.988368</td>\n",
       "      <td>0.056522</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.040277</td>\n",
       "      <td>0.988368</td>\n",
       "      <td>0.055098</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.039821</td>\n",
       "      <td>0.988026</td>\n",
       "      <td>0.054019</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.038609</td>\n",
       "      <td>0.988026</td>\n",
       "      <td>0.057750</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.038992</td>\n",
       "      <td>0.989394</td>\n",
       "      <td>0.054025</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.039881</td>\n",
       "      <td>0.988026</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.040840</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.054421</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.039914</td>\n",
       "      <td>0.987684</td>\n",
       "      <td>0.056689</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.037566</td>\n",
       "      <td>0.989052</td>\n",
       "      <td>0.060733</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.044597</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.059645</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.042627</td>\n",
       "      <td>0.986658</td>\n",
       "      <td>0.056932</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.049010</td>\n",
       "      <td>0.984263</td>\n",
       "      <td>0.071320</td>\n",
       "      <td>0.981538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.048367</td>\n",
       "      <td>0.983921</td>\n",
       "      <td>0.055227</td>\n",
       "      <td>0.982564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.045642</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.064368</td>\n",
       "      <td>0.979487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.043672</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.057390</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.041381</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.054303</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.041462</td>\n",
       "      <td>0.986315</td>\n",
       "      <td>0.054067</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.038877</td>\n",
       "      <td>0.989052</td>\n",
       "      <td>0.054656</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.038395</td>\n",
       "      <td>0.988710</td>\n",
       "      <td>0.053475</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "110  0.043804  0.985973  0.057355      0.984615\n",
       "111  0.040324  0.988368  0.054346      0.985641\n",
       "112  0.038798  0.988710  0.053584      0.984615\n",
       "113  0.039561  0.988710  0.058421      0.986667\n",
       "114  0.043663  0.987342  0.062238      0.983590\n",
       "115  0.040798  0.987000  0.055796      0.983590\n",
       "116  0.040098  0.988710  0.055392      0.985641\n",
       "117  0.043736  0.987342  0.060652      0.983590\n",
       "118  0.039868  0.986315  0.056128      0.983590\n",
       "119  0.040674  0.988368  0.053366      0.984615\n",
       "120  0.041093  0.988026  0.055438      0.985641\n",
       "121  0.039716  0.988368  0.056522      0.985641\n",
       "122  0.040277  0.988368  0.055098      0.985641\n",
       "123  0.039821  0.988026  0.054019      0.983590\n",
       "124  0.038609  0.988026  0.057750      0.985641\n",
       "125  0.038992  0.989394  0.054025      0.984615\n",
       "126  0.039881  0.988026  0.055655      0.983590\n",
       "127  0.040840  0.987342  0.054421      0.985641\n",
       "128  0.039914  0.987684  0.056689      0.985641\n",
       "129  0.037566  0.989052  0.060733      0.984615\n",
       "130  0.044597  0.987000  0.059645      0.985641\n",
       "131  0.042627  0.986658  0.056932      0.985641\n",
       "132  0.049010  0.984263  0.071320      0.981538\n",
       "133  0.048367  0.983921  0.055227      0.982564\n",
       "134  0.045642  0.987000  0.064368      0.979487\n",
       "135  0.043672  0.987342  0.057390      0.985641\n",
       "136  0.041381  0.987342  0.054303      0.985641\n",
       "137  0.041462  0.986315  0.054067      0.985641\n",
       "138  0.038877  0.989052  0.054656      0.985641\n",
       "139  0.038395  0.988710  0.053475      0.985641"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e20fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c7662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c69ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b436e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
