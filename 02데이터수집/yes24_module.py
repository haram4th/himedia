{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7de4d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # 서버에 http 프로토콜로 요청\n",
    "from bs4 import BeautifulSoup as bs  # html 파싱\n",
    "import time  # 5초간 휴식 할 때 사용\n",
    "from datetime import datetime  # 오늘 연월일 추출\n",
    "import pandas as pd  # 데이터 프레임 만듬\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# book_list에서 책 1권의 정보를 추출하는 함수\n",
    "def extract_bookinfo(yy, mon, book_list):\n",
    "    for book in book_list:\n",
    "        title_h = book.select_one(\".gd_res\").get_text()\n",
    "        title_f = book.select_one(\".gd_nameF\").get_text() if book.select_one(\".gd_nameF\") != None else \"\"\n",
    "        title_m = book.select_one(\".gd_name\").get_text() if book.select_one(\".gd_name\") != None else \"제목없음\"\n",
    "        title_e = book.select_one(\".gd_nameE\").get_text() if book.select_one(\".gd_nameE\") != None else \"\"\n",
    "        detail_link = \"https://www.yes24.com\" + book.select_one(\".gd_name\")[\"href\"] if book.select_one(\".gd_name\") != None else \"제목없음\"\n",
    "        author = [i.get_text() for i in book.select(\".authPub.info_auth > a\") if book.select(\".authPub.info_auth > a\") != None]\n",
    "        publisher = book.select_one(\".authPub.info_pub > a\").get_text() if book.select_one(\".authPub.info_pub > a\") != None else \"\"\n",
    "        pub_date = book.select_one(\".authPub.info_date\").get_text() if book.select_one(\".authPub.info_date\") != None else \"\"\n",
    "        price = book.select_one(\".yes_b\").get_text() if book.select_one(\".yes_b\") != None else 0\n",
    "        n_reviews = book.select_one(\".txC_blue\").get_text() if book.select_one(\".txC_blue\") != None else 0\n",
    "        review_link = book.select_one(\".rating_rvCount > a\")['href'] if book.select_one(\".rating_rvCount > a\") != None else \"\"\n",
    "        rating = book.select_one(\"span.rating_grade > .yes_b\").get_text() if book.select_one(\"span.rating_grade > .yes_b\") != None else 0\n",
    "        tags = [i.get_text() for i in book.select(\".info_row.info_tag > .tag > a\") if book.select(\".info_row.info_tag > .tag > a\") != None]\n",
    "        return [yy, mon, title_h, title_f, title_m, title_e, detail_link, author, publisher, pub_date, price, n_reviews,\n",
    "             review_link, rating, tags]\n",
    "    \n",
    "def detail_page_info(urls):\n",
    "    detail_result = pd.DataFrame()\n",
    "    for index, url2 in enumerate(urls[:10]):\n",
    "        print(f\"{index}/{len(urls)} 데이터 추출 중\")\n",
    "        r2 = requests.get(url2)\n",
    "        soup2 = bs(r2.text, 'lxml')\n",
    "        book_id = url2.split(\"/\")[-1]\n",
    "        if soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(2) > td\") != None:\n",
    "            if \"쪽수\" in soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(2) > th\").text:\n",
    "                if len(soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(2) > td\").text.split(\"|\")) == 3:\n",
    "                    page, weight, size = soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(2) > td\").text.split(\"|\")\n",
    "                elif len(soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(2) > td\").text.split(\"|\")) == 2 and \\\n",
    "                       soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(2) > td\").text.split(\"|\")[1][-2:] == \"mm\":\n",
    "                    page, size = soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(2) > td\").text.split(\"|\")\n",
    "                    weight = 0\n",
    "            elif \"쪽수\" in soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(3) > th\").text:\n",
    "                if len(soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(3) > td\").text.split(\"|\")) == 3:\n",
    "                    page, weight, size = soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(3) > td\").text.split(\"|\")\n",
    "                elif len(soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(3) > td\").text.split(\"|\")) == 2 and \\\n",
    "                   soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(3) > td\").text.split(\"|\")[1][-2:] == \"mm\":\n",
    "                    page, size = soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(3) > td\").text.split(\"|\")\n",
    "                    weight = 0\n",
    "            elif \"쪽수\" in soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(4) > th\").text:\n",
    "                if len(soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(4) > td\").text.split(\"|\")) == 3:\n",
    "                    page, weight, size = soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(4) > td\").text.split(\"|\")\n",
    "                elif len(soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(4) > td\").text.split(\"|\")) == 2 and \\\n",
    "                       soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(4) > td\").text.split(\"|\")[1][-2:] == \"mm\":\n",
    "                        page, size = soup2.select_one(\"div.infoSetCont_wrap tr:nth-child(4) > td\").text.split(\"|\")\n",
    "                        weight = 0\n",
    "        else:\n",
    "            page = 0\n",
    "            weight = 0\n",
    "            size = \"\"\n",
    "        category = list({i. text for i in soup2.select(\"div.infoSetCont_wrap > dl:nth-child(1) > dd > ul a\") if soup2.select(\"div.infoSetCont_wrap > dl:nth-child(1) > dd > ul a\") != None})\n",
    "        book_intro = soup2.select_one(\".infoWrap_txtInner\").get_text() if soup2.select_one(\".infoWrap_txtInner\") != None else \"\"\n",
    "        pub_book_intro = soup2.select_one(\".infoWrap_txt\").get_text() if soup2.select_one(\".infoWrap_txt\") != None else \"\"\n",
    "\n",
    "        result_detail = [book_id, page, weight, size, category, book_intro, pub_book_intro]\n",
    "        colname = ['book_id', 'page', 'weight', 'size', 'category', 'book_intro', 'pub_book_intro']\n",
    "        temp = pd.DataFrame([result_detail], columns = colname)\n",
    "        detail_result = pd.concat([detail_result, temp])\n",
    "        detail_result.to_csv(\"./data/yes24_2023_01best_detail.csv\", index=False)\n",
    "    return detail_result\n",
    "\n",
    "def to_db(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(str)    \n",
    "    engine = create_engine('sqlite:///yes24_final.db', echo= False)\n",
    "    conn = engine.raw_connection()\n",
    "    df.to_sql('yes24_final_fn', con=conn, if_exists='append')\n",
    "    print(\"데이터베이스 저장 완료\")\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
